{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m# function called on the frame\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m image_for_prediction \u001b[39m=\u001b[39m eye_cropper(frame)\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     image_for_prediction \u001b[39m=\u001b[39m image_for_prediction\u001b[39m/\u001b[39m\u001b[39m255.0\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m, in \u001b[0;36meye_cropper\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meye_cropper\u001b[39m(frame):\n\u001b[1;32m     16\u001b[0m     \u001b[39m# create a variable for the facial feature coordinates\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     facial_features_list \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39;49mface_landmarks(frame)\n\u001b[1;32m     19\u001b[0m     \u001b[39m# create a placeholder list for the eye coordinates\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m# and append coordinates for eyes to list unless eyes\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# weren't found by facial recognition\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/face_recognition/api.py:177\u001b[0m, in \u001b[0;36mface_landmarks\u001b[0;34m(face_image, face_locations, model)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mface_landmarks\u001b[39m(face_image, face_locations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlarge\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m    Given an image, returns a dict of face feature locations (eyes, nose, etc) for each face in the image\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39m    :return: A list of dicts of face feature locations (eyes, nose, etc)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     landmarks \u001b[39m=\u001b[39m _raw_face_landmarks(face_image, face_locations, model)\n\u001b[1;32m    178\u001b[0m     landmarks_as_tuples \u001b[39m=\u001b[39m [[(p\u001b[39m.\u001b[39mx, p\u001b[39m.\u001b[39my) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m landmark\u001b[39m.\u001b[39mparts()] \u001b[39mfor\u001b[39;00m landmark \u001b[39min\u001b[39;00m landmarks]\n\u001b[1;32m    180\u001b[0m     \u001b[39m# For a definition of each point index, see https://cdn-images-1.medium.com/max/1600/1*AbEg31EgkbXSQehuNJBlWg.png\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/face_recognition/api.py:156\u001b[0m, in \u001b[0;36m_raw_face_landmarks\u001b[0;34m(face_image, face_locations, model)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raw_face_landmarks\u001b[39m(face_image, face_locations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlarge\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    155\u001b[0m     \u001b[39mif\u001b[39;00m face_locations \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m         face_locations \u001b[39m=\u001b[39m _raw_face_locations(face_image)\n\u001b[1;32m    157\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         face_locations \u001b[39m=\u001b[39m [_css_to_rect(face_location) \u001b[39mfor\u001b[39;00m face_location \u001b[39min\u001b[39;00m face_locations]\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/face_recognition/api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m face_detector(img, number_of_times_to_upsample)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from playsound import playsound\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "from tensorflow import keras\n",
    "\n",
    "eye_model = keras.models.load_model(\n",
    "    r'/Users/kronos27/Desktop/Driver Drowsiness Detection/ProjectData/models_inceptionV3/models.h5')\n",
    "\n",
    "# webcam frame is inputted into function\n",
    "\n",
    "\n",
    "def eye_cropper(frame):\n",
    "    # create a variable for the facial feature coordinates\n",
    "    facial_features_list = face_recognition.face_landmarks(frame)\n",
    "\n",
    "    # create a placeholder list for the eye coordinates\n",
    "    # and append coordinates for eyes to list unless eyes\n",
    "    # weren't found by facial recognition\n",
    "    try:\n",
    "        eye = facial_features_list[0]['left_eye']\n",
    "    except:\n",
    "        try:\n",
    "            eye = facial_features_list[0]['right_eye']\n",
    "        except:\n",
    "            return\n",
    "\n",
    "    # establish the max x and y coordinates of the eye\n",
    "    x_max = max([coordinate[0] for coordinate in eye])\n",
    "    x_min = min([coordinate[0] for coordinate in eye])\n",
    "    y_max = max([coordinate[1] for coordinate in eye])\n",
    "    y_min = min([coordinate[1] for coordinate in eye])\n",
    "\n",
    "    # establish the range of x and y coordinates\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "\n",
    "    # in order to make sure the full eye is captured,\n",
    "    # 50% cushion added to the axis with a larger range and\n",
    "    # then match the smaller range to the cushioned larger range\n",
    "    if x_range > y_range:\n",
    "        right = round(.5*x_range) + x_max\n",
    "        left = x_min - round(.5*x_range)\n",
    "        bottom = round((((right-left) - y_range))/2) + y_max\n",
    "        top = y_min - round((((right-left) - y_range))/2)\n",
    "    else:\n",
    "        bottom = round(.5*y_range) + y_max\n",
    "        top = y_min - round(.5*y_range)\n",
    "        right = round((((bottom-top) - x_range))/2) + x_max\n",
    "        left = x_min - round((((bottom-top) - x_range))/2)\n",
    "\n",
    "    # crop the image according to the coordinates determined above\n",
    "    cropped = frame[top:(bottom + 1), left:(right + 1)]\n",
    "\n",
    "    # resize the image\n",
    "    cropped = cv2.resize(cropped, (128, 128))\n",
    "    image_for_prediction = cropped.reshape(-1, 128, 128, 3)\n",
    "    return image_for_prediction\n",
    "\n",
    "\n",
    "# initiate webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "opened = cap.isOpened()\n",
    "x=0\n",
    "if not opened:\n",
    "    x=1\n",
    "    raise IOError('Cannot open webcam')\n",
    "\n",
    "# set a counter\n",
    "counter = 0\n",
    "\n",
    "# create a while loop that runs while webcam is in use\n",
    "while True:\n",
    "    # capture frames being outputted by webcam\n",
    "    x=2\n",
    "    ret, frame = cap.read()\n",
    "    x=3\n",
    "    # use only every other frame to manage speed and memory usage\n",
    "    frame_count = 0\n",
    "\n",
    "    if frame_count == 0:\n",
    "        frame_count += 1\n",
    "        pass\n",
    "    else:\n",
    "        count = 0\n",
    "        continue\n",
    "\n",
    "    # function called on the frame\n",
    "    image_for_prediction = eye_cropper(frame)\n",
    "\n",
    "    try:\n",
    "        image_for_prediction = image_for_prediction/255.0\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # get prediction from model\n",
    "    prediction = eye_model.predict(image_for_prediction)\n",
    "\n",
    "    # Based on prediction, display either \"Open Eyes\" or \"Closed Eyes\"\n",
    "    if prediction > 0.5:\n",
    "\n",
    "        counter = 0\n",
    "        status = 'Open'\n",
    "        cv2.rectangle(frame, (round(w/2) - 110, 20),\n",
    "                      (round(w/2) + 110, 80), (38, 38, 38), -1)\n",
    "        cv2.putText(frame, status, (round(w/2)-80, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv2.LINE_4)\n",
    "        x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "        # Draw black background rectangle\n",
    "        cv2.rectangle(frame, (x1, x1), (x1+w1-20, y1+h1-20), (0, 0, 0), -1)\n",
    "        # Add text\n",
    "        cv2.putText(frame, 'Active', (x1+int(w1/10), y1+int(h1/2)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        status = 'Closed'\n",
    "        cv2.rectangle(frame, (round(w/2) - 110, 20),\n",
    "                      (round(w/2) + 110, 80), (38, 38, 38), -1)\n",
    "        cv2.putText(frame, status, (round(w/2)-104, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_4)\n",
    "        x1, y1, w1, h1 = 0, 0, 175, 75\n",
    "        # Draw black background rectangle\n",
    "        cv2.rectangle(frame, (x1, x1), (x1+w1-20, y1+h1-20), (0, 0, 0), -1)\n",
    "        # Add text\n",
    "        cv2.putText(frame, 'Active', (x1+int(w1/10), y1+int(h1/2)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # if the counter is greater than 3, play and show alert that user is asleep\n",
    "    \n",
    "    if counter > 2:\n",
    "        # Draw black background rectangle\n",
    "        cv2.rectangle(frame, (round(w/2) - 160, round(h) - 200),\n",
    "                      (round(w/2) + 160, round(h) - 120), (0, 0, 255), -1)\n",
    "        cv2.putText(frame, 'DRIVER SLEEPING', (round(w/2)-136, round(h) - 146),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_4)\n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        k = cv2.waitKey(1)\n",
    "        # Sound\n",
    "        playsound(\n",
    "            r'/Users/kronos27/Desktop/Driver Drowsiness Detection/ProjectData/alarm.wav')\n",
    "        counter = 1\n",
    "        continue\n",
    "    x=4\n",
    "    cv2.imshow('frame', frame)\n",
    "    x=5\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        x=27\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
